{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator API Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from perturbench.analysis.benchmarks.evaluator import Evaluator\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we'll be demonstrating the usage of the Evaluator API using the srivatsan20-transfer task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Evaluator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all tasks in the Evaluator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['srivatsan20-transfer',\n",
       " 'mcfaline23-transfer',\n",
       " 'norman19-combo',\n",
       " 'frangieh21-transfer',\n",
       " 'jiang24-transfer']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluator.list_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an evaluator object with the srivatsan20-transfer task. It will automatically download and process the srivatsan20 dataset for you. For the mcfaline23-transfer and jiang24-transfer tasks, you will need to run the notebooks in the notebooks/neurips2024/data_curation/ directory first to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data from: ../neurips2024/perturbench_data/sciplex3_processed.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/weka/ywu/git-repos/perturbench/src/perturbench/data/datasplitter.py:342: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for cov_keys, df in self.obs_dataframe.groupby(self.covariate_keys):\n",
      "/weka/ywu/git-repos/perturbench/src/perturbench/data/datasplitter.py:352: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for pert_key, df in self.obs_dataframe.groupby([self.perturbation_key]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split summary: \n",
      "           train  val  test\n",
      "('mcf7',)    132   29    30\n",
      "('a549',)    132   30    29\n",
      "('k562',)    132   29    30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<perturbench.analysis.benchmarks.evaluator.Evaluator at 0x7fa95526c450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srivatsan20_eval = Evaluator(\n",
    "    task='srivatsan20-transfer',\n",
    "    local_data_cache='../neurips2024/perturbench_data',\n",
    ")\n",
    "srivatsan20_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pull the train/test/val splits as a dictionary of cell indexes from the evaluator object with the `get_split` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 123044\n",
      "val 28454\n",
      "test 32358\n"
     ]
    }
   ],
   "source": [
    "split_dict = srivatsan20_eval.get_split()\n",
    "for k,v in split_dict.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate perturbation response predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluator object requires a dictionary of perturbation response predictions as anndata objects. For this demo, we'll simulate these predictions by randomly subsampling and/or shuffling the data and treating those samples/shuffles as different \"model predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 28454 × 9198\n",
       "    obs: 'ncounts', 'well', 'plate', 'cell_line', 'replicate', 'time', 'dose_value', 'pathway_level_1', 'pathway_level_2', 'perturbation', 'target', 'pathway', 'dose_unit', 'celltype', 'disease', 'cancer', 'tissue_type', 'organism', 'perturbation_type', 'ngenes', 'percent_mito', 'percent_ribo', 'nperts', 'chembl-ID', 'cell_type', 'condition', 'cov_merged', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'transfer_split_seed42'\n",
       "    var: 'ensembl_id', 'ncounts', 'ncells', 'gene_symbol', 'n_cells', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
       "    uns: 'hvg', 'log1p', 'rank_genes_groups_cov'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = srivatsan20_eval.ref_adata\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate predictions by randomly subsampling and/or shuffling the data and treating those samples/shuffles as different \"model predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['condition_cell_type'] = adata.obs['condition'].astype(str) + '_' + adata.obs['cell_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cells, _ = train_test_split(\n",
    "    adata.obs_names,\n",
    "    test_size=0.25, \n",
    "    stratify=adata.obs['condition_cell_type'],\n",
    "    random_state=54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21340, 9198)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_adata = adata[sampled_cells, :]\n",
    "sampled_adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create the shuffled predictions to serve as a negative control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21340, 9198)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(54)\n",
    "\n",
    "random_adata_list = []\n",
    "for cell_type in sampled_adata.obs.cell_type.unique():\n",
    "    random_adata_cl = sampled_adata[sampled_adata.obs.cell_type == cell_type, :].copy()\n",
    "    random_adata_cl.obs['condition'] = random.sample(\n",
    "        list(random_adata_cl.obs['condition'].astype(str)), \n",
    "        k=random_adata_cl.n_obs,\n",
    "    )\n",
    "    random_adata_list.append(random_adata_cl)\n",
    "\n",
    "random_adata = ad.concat(random_adata_list)\n",
    "random_adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to our evaluator class is a dictionary of model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_predictions = {\n",
    "    'sampled': sampled_adata,\n",
    "    'random': random_adata,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our simulated model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/weka/ywu/git-repos/perturbench/src/perturbench/analysis/benchmarks/evaluation.py:93: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata_i.obs[pert_col] = adata_i.obs[pert_col].astype(\"category\")\n",
      "/weka/ywu/git-repos/perturbench/src/perturbench/analysis/benchmarks/aggregation.py:259: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[pert_col] = adata.obs[pert_col].astype(\"category\")\n",
      "/weka/ywu/git-repos/perturbench/src/perturbench/analysis/benchmarks/evaluator.py:197: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  summary_metrics = pd.DataFrame(summary_metrics_dict).T.applymap(\n"
     ]
    }
   ],
   "source": [
    "metrics_df = srivatsan20_eval.evaluate(\n",
    "    model_predictions=simulated_predictions,\n",
    "    return_metrics_dataframe=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at the summary metrics returned by the evaluation. This is an average of the metric computed on a per-perturbation basis. As we can see, the sampled data is very close to the full observed data and the random data has no information at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>random</th>\n",
       "      <th>sampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_average</th>\n",
       "      <td>0.02680</td>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_rank_average</th>\n",
       "      <td>0.45740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_logfc</th>\n",
       "      <td>0.01067</td>\n",
       "      <td>0.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_rank_logfc</th>\n",
       "      <td>0.41970</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model               random   sampled\n",
       "rmse_average       0.02680  0.005791\n",
       "rmse_rank_average  0.45740  0.000000\n",
       "cosine_logfc       0.01067  0.919500\n",
       "cosine_rank_logfc  0.41970  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perturbench-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
